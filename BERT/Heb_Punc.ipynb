{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7859,
     "status": "ok",
     "timestamp": 1555865223848,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "4x-2NqzpxNYi",
    "outputId": "7b55a20d-1de5-4d18-bb8f-5c81502dbcd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval==0.0.5 in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.5) (1.16.2)\n",
      "Requirement already satisfied: pytorch_pretrained_bert==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.9.130)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.0.1.post2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (4.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.16.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (1.12.130)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (0.2.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (2019.3.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert==0.4.0) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert==0.4.0) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert==0.4.0) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval==0.0.5\n",
    "!pip install pytorch_pretrained_bert==0.4.0\n",
    "\n",
    "import os\n",
    "\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_V3YcmWMy8UY"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1555865647973,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "q0EkRyQKy977",
    "outputId": "a1d0ddcf-8d5e-4da3-e3bb-79b80956d3c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data: 4036\n",
      "-----------------------------------------------------\n",
      "['השימוש', 'הראשון', 'המוכר', 'במונח', 'קפיטליזם', 'מופיע', 'אצל', 'תאקרי', 'בשנת', '0', 'במשמעות', 'בעלות', 'על', 'הון', 'השימוש', 'המודרני', 'הרחב', 'הראשון', 'במונח', 'בא', 'בספר', 'הקפיטל', 'של', 'קרל', 'מרקס', 'ופרידריך', 'אנגלס', 'המתייחס', 'למערכת', 'הייצור', 'הקפיטליסטית', 'ול', 'קפיטליסט', 'במובן', 'של', 'בעלים', 'של', 'אמצעי', 'הייצור', 'שימושם', 'המקורי', 'של', 'מרקס', 'ואנגלס', 'במונח', 'היה', 'ככינוי', 'גנאי', 'מאקס', 'ובר', 'השתמש', 'בו', 'בחיבורו', 'הידוע', 'האתיקה', 'הפרוטסטנטית', 'ורוח', 'הקפיטליזם', 'אך', 'רק', 'לאחר', 'פרסום', 'ספרו', 'של', 'הכלכלן', 'ורנר', 'זומברט', 'קפיטליזם', 'מודרני', 'משנת', '0', 'המונח', 'הפך', 'לתיאור', 'תפיסה', 'המנוגדת', 'לסוציאליזם', 'כיום', 'אף', 'שאדם', 'סמית', 'לא', 'השתמש', 'מעולם', 'במונח', 'קפיטליזם', 'ותיאר', 'את', 'המערכת', 'הכלכלית', 'המועדפת', 'עליו', 'כ', 'מערכת', 'החירות', 'הטבעית', 'יש', 'הרואים', 'בו', 'אבי', 'הקפיטליזם']\n",
      "-----------------------------------------------------\n",
      "['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', '.']\n"
     ]
    }
   ],
   "source": [
    "def getStringFromDataFile(fname):\n",
    "    dataFilePath    = fname\n",
    "    dataFile        = open(dataFilePath, \"r\", encoding='utf-8')\n",
    "    dataStr         = dataFile.read()\n",
    "    # print(dataStr)\n",
    "    return dataStr\n",
    "\n",
    "\n",
    "def generate_dataset_part_a(outname):\n",
    "    out = getStringFromDataFile(outname)\n",
    "    out = out.split(\"<DATADEL>\")  \n",
    "    data = []\n",
    "    for x in out:\n",
    "        data.append(x.split(\"<XYDEL>\"))\n",
    "    dataset=[]\n",
    "    for d in data:\n",
    "        temp = []\n",
    "        temp.append(d[0].split(\" \"))\n",
    "        temp.append(d[1].split(\" \"))\n",
    "        dataset.append(temp)\n",
    "    return dataset\n",
    "\n",
    "data = generate_dataset_part_a(\"train_data\")\n",
    "x_train = [x[0] for x in data]\n",
    "y_train = [x[1] for x in data]\n",
    "print(\"size of data: \" + str(len(x_train)))\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(x_train[0])\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuSoekHVYy-k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12202,
     "status": "ok",
     "timestamp": 1555865696727,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "kYuYrMvU0fS_",
    "outputId": "4506239d-65bf-42a0-f5ba-cfeaf5b6a63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['השימוש', 'הראשון', 'ה', '##מו', '##כר', 'ב', '##מו', '##נח', 'ק', '##פי', '##טל', '##יז', '##ם', 'מופיע', 'אצל', 'ת', '##אק', '##רי', 'בשנת', '0', 'ב', '##מש', '##מעות', 'בעלות', 'על', 'ה', '##ון', 'השימוש', 'ה', '##מוד', '##רני', 'הר', '##חב', 'הראשון', 'ב', '##מו', '##נח', 'ב', '##א', 'בספר', 'ה', '##ק', '##פי', '##טל', 'של', 'ק', '##רל', 'מ', '##רק', '##ס', 'ו', '##פר', '##יד', '##ריך', 'אנג', '##לס', 'ה', '##מת', '##יי', '##חס', 'ל', '##מערכת', 'ה', '##יי', '##צור', 'ה', '##ק', '##פי', '##טל', '##יס', '##טית', 'ו', '##ל', 'ק', '##פי', '##טל', '##יס', '##ט', 'ב', '##מו', '##בן', 'של', 'בעלי', '##ם', 'של', 'א', '##מ', '##צע', '##י', 'ה', '##יי', '##צור', 'שימוש', '##ם', 'המקורי', 'של', 'מ', '##רק', '##ס', 'ו', '##א', '##נג', '##לס', 'ב', '##מו', '##נח', 'היה', 'כ', '##כי', '##נוי', 'ג', '##נאי', 'מ', '##אק', '##ס', 'וב', '##ר', 'ה', '##שתמש', 'בו', 'ב', '##חי', '##בור', '##ו', 'ה', '##ידוע', 'ה', '##את', '##יקה', 'ה', '##פר', '##וט', '##סט', '##נטית', 'ו', '##רו', '##ח', 'ה', '##ק', '##פי', '##טל', '##יז', '##ם', 'אך', 'רק', 'לאחר', 'פרס', '##ום', 'ספרו', 'של', 'הכל', '##כל', '##ן', 'ו', '##ר', '##נר', 'זו', '##מבר', '##ט', 'ק', '##פי', '##טל', '##יז', '##ם', 'מ', '##וד', '##רני', 'משנת', '0', 'ה', '##מו', '##נח', 'הפך', 'ל', '##תי', '##אור', 'ת', '##פי', '##סה', 'ה', '##מנו', '##ג', '##דת', 'ל', '##סו', '##צי', '##אלי', '##זם', 'כיום', 'אף', 'ש', '##אד', '##ם', 'ס', '##מית', 'לא', 'ה', '##שתמש', 'מ', '##עולם', 'ב', '##מו', '##נח', 'ק', '##פי', '##טל', '##יז', '##ם', 'ו', '##תי', '##אר', 'את', 'ה', '##מערכת', 'הכל', '##כלית', 'ה', '##מו', '##עד', '##פת', 'עליו', 'כ', 'מערכת', 'ה', '##חי', '##רות', 'ה', '##טבע', '##ית', 'יש', 'הר', '##ואים', 'בו', 'א', '##בי', 'ה', '##ק', '##פי', '##טל', '##יז', '##ם']\n",
      "['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', 'none', '.', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', '.', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', '.', '.', '.', '.', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', ',', ',', ',', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', ',', ',', 'none', 'none', 'none', 'none', 'none', 'none', '.', '.', '.', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "def tokenize(sentences, orig_labels):\n",
    "    tokenized_texts = []\n",
    "    labels = []\n",
    "    for sent, sent_labels in zip(sentences, orig_labels):\n",
    "        bert_tokens = []\n",
    "        bert_labels = []\n",
    "        for orig_token, orig_label in zip(sent, sent_labels):\n",
    "            b_tokens = tokenizer.tokenize(orig_token)\n",
    "            bert_tokens.extend(b_tokens)\n",
    "            for b_token in b_tokens:\n",
    "                bert_labels.append(orig_label)\n",
    "        tokenized_texts.append(bert_tokens)\n",
    "        labels.append(bert_labels)\n",
    "\n",
    "        assert len(bert_tokens) == len(bert_labels)\n",
    "\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "\n",
    "train_tokenized_texts, train_labels = tokenize(x_train, y_train)\n",
    "print(train_tokenized_texts[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoBTBV9q0rDb"
   },
   "outputs": [],
   "source": [
    "tags_vals = ['none', ',','.','!','?']\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "idx2tag = {i: t for i, t in enumerate(tags_vals)}\n",
    "\n",
    "MAX_LEN = 200 ####TO_DO\n",
    "bs = 32 ####TO_DO_TOO\n",
    "\n",
    "def pad_sentences_and_labels(tokenized_texts, labels):\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                         maxlen=MAX_LEN, value=tag2idx[\"none\"], padding=\"post\",\n",
    "                         dtype=\"long\", \n",
    "                         truncating=\"post\")\n",
    "\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    return input_ids, tags, attention_masks\n",
    "  \n",
    "\n",
    "input_ids, tags, attention_masks = pad_sentences_and_labels(train_tokenized_texts, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h82qtNZM00Vq"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(input_ids)\n",
    "tr_tags = torch.tensor(tags)\n",
    "tr_masks = torch.tensor(attention_masks)\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1555865781006,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "lWs4Mqh404l6",
    "outputId": "5b604f11-6d70-4868-fa0c-8e4865cd58e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of gpus: 1\n",
      "Name of gpu: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "print(\"Device: \" + str(device))\n",
    "print(\"Number of gpus: \" + str(n_gpu))\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Name of gpu: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kd5fZjVP079T"
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=len(tag2idx))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "FULL_FINETUNING = False\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "max_grad_norm = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1005
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8583022,
     "status": "ok",
     "timestamp": 1555874465370,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "ySOdPYRm1GFB",
    "outputId": "7f56306c-cad5-4ce3-8cda-4614ee0b6c4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 1/50 [02:53<2:21:29, 173.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4419150408797377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [05:45<2:18:17, 172.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9609540672752801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [08:37<2:15:10, 172.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6981236723464305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [11:28<2:12:08, 172.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5692990797711169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [14:21<2:09:14, 172.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5002727860540855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [17:12<2:06:14, 172.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4605564188769483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [20:05<2:03:21, 172.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4351503299915884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [22:56<2:00:21, 171.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.41978501780765265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [25:48<1:57:26, 171.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.40931926210095565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [28:39<1:54:30, 171.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3997392703698376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [31:31<1:51:40, 171.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.392607447903926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [34:23<1:48:44, 171.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.38767448513526614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [37:15<1:45:55, 171.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3822888807048948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [40:06<1:43:01, 171.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3787605807067841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 15/50 [42:57<1:40:06, 171.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.37463710885348284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  32%|███▏      | 16/50 [45:49<1:37:12, 171.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.37075219262303327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  34%|███▍      | 17/50 [48:40<1:34:14, 171.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.36807674685801106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  36%|███▌      | 18/50 [51:31<1:31:24, 171.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3659530833480865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|███▊      | 19/50 [54:23<1:28:36, 171.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.362909797843047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 20/50 [57:15<1:25:50, 171.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3609900575453841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  42%|████▏     | 21/50 [1:00:07<1:23:01, 171.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.35920319876332923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|████▍     | 22/50 [1:02:59<1:20:06, 171.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3570449896684782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  46%|████▌     | 23/50 [1:05:50<1:17:15, 171.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.35546216884935933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  48%|████▊     | 24/50 [1:08:42<1:14:20, 171.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3535249862145251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 25/50 [1:11:33<1:11:31, 171.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.35161933866072825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  52%|█████▏    | 26/50 [1:14:25<1:08:40, 171.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3508152457203452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  54%|█████▍    | 27/50 [1:17:16<1:05:45, 171.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3496148424355064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████▌    | 28/50 [1:20:07<1:02:50, 171.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34826602499316056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  58%|█████▊    | 29/50 [1:22:59<1:00:02, 171.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3473435295379068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 30/50 [1:25:51<57:11, 171.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34614056841594965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  62%|██████▏   | 31/50 [1:28:43<54:20, 171.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3450564544970595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  64%|██████▍   | 32/50 [1:31:34<51:29, 171.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34428503405390765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  66%|██████▌   | 33/50 [1:34:26<48:37, 171.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34383144317649483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  68%|██████▊   | 34/50 [1:37:17<45:45, 171.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34284112491006924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 35/50 [1:40:09<42:53, 171.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3421639330743805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|███████▏  | 36/50 [1:43:00<40:00, 171.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34152156443107784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  74%|███████▍  | 37/50 [1:45:51<37:08, 171.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3403604403724821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  76%|███████▌  | 38/50 [1:48:43<34:16, 171.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33925156166234355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|███████▊  | 39/50 [1:51:34<31:24, 171.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3397988616012213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 40/50 [1:54:26<28:34, 171.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3385190747854278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  82%|████████▏ | 41/50 [1:57:17<25:43, 171.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3382828350611559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  84%|████████▍ | 42/50 [2:00:09<22:52, 171.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33724569546894767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 43/50 [2:03:00<20:00, 171.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3367642286255604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  88%|████████▊ | 44/50 [2:05:52<17:09, 171.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3362450796788133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 45/50 [2:08:44<14:17, 171.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33579028192467575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  92%|█████████▏| 46/50 [2:11:35<11:26, 171.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3353537307010861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|█████████▍| 47/50 [2:14:27<08:34, 171.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33552952474496495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  96%|█████████▌| 48/50 [2:17:19<05:43, 171.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33479553953869134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  98%|█████████▊| 49/50 [2:20:10<02:51, 171.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3345003496474168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 50/50 [2:23:02<00:00, 171.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33491588436712433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,\n",
    "                     labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1555875297177,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "j60X9_8SY1G_",
    "outputId": "06e1f1e0-234f-4947-f8f1-8112afaeb90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "['פילוסופיה', 'של', 'המדע', 'הוא', 'ענף', 'בפילוסופיה', 'העוסק', 'ביסודות', 'הנחות', 'ובמשמעויות', 'הפילוסופיות', 'של', 'המדעים', 'ענף', 'מגוון', 'זה', 'מתייחס', 'לכל', 'המדעים', 'מדעי', 'הטבע', 'כגון', 'פיזיקה', 'וביולוגיה', 'מדעי', 'החברה', 'כגון', 'פסיכולוגיה', 'וכלכלה', 'ומדעי', 'הרוח', 'יש', 'הרואים', 'בפילוסופיה', 'של', 'המדע', 'אפיסטמולוגיה', 'ואף', 'מטאפיזיקה', 'של', 'המדע', 'הממשי', 'הפילוסופיה', 'של', 'המדע', 'שואפת', 'לענות', 'ולהסביר', 'שאלות', 'כגון', 'טבעם', 'של', 'קביעות', 'ומושגים', 'מדעיים', 'האופן', 'שבו', 'הם', 'נוצרים', 'כיצד', 'המדע', 'מסביר', 'חוזה', 'ומשתמש', 'בטבע', 'באמצעות', 'טכנולוגיה', 'כיצד', 'אפשר', 'להחליט', 'על', 'הדיוק', 'של', 'מידע', 'הניסוח', 'והשימוש', 'במתודות', 'מדעיות', 'אופני', 'החשיבה', 'שבהם', 'משתמשים', 'על', 'מנת', 'להגיע', 'למסקנות', 'והמשמעויות', 'של', 'המתודות', 'והמודלים', 'המדעיים', 'לחברה', 'ככלל', 'ולמדעים', 'עצמם']\n",
      "-----------------------------------------------------\n",
      "['none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', '.', 'none', 'none', 'none', 'none', 'none', ',', 'none', ',', 'none', 'none', ',', 'none', ',', 'none', 'none', ',', 'none', '.', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', '.', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', ',', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ',', 'none', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def generate_dataset_part_a(outname):\n",
    "    out = getStringFromDataFile(outname)\n",
    "    out = out.split(\"<DATADEL>\")  \n",
    "    data = []\n",
    "    for x in out:\n",
    "        data.append(x.split(\"<XYDEL>\"))\n",
    "    dataset=[]\n",
    "    for d in data:\n",
    "        temp = []\n",
    "        temp.append(d[0].split(\" \"))\n",
    "        temp.append(d[1].split(\" \"))\n",
    "        dataset.append(temp)\n",
    "    return dataset\n",
    "\n",
    "data = generate_dataset_part_a(\"test_data\")\n",
    "x_test = [x[0] for x in data]\n",
    "y_test = [x[1] for x in data]\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(x_test[0])\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5193,
     "status": "ok",
     "timestamp": 1555879572185,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "2wECFfZNZy77",
    "outputId": "9bcd4570-0e37-4124-9eb6-b23c2321459b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.304429829120636\n",
      "Validation Accuracy: 0.89375\n",
      "F1-Score: 0.022963367960634227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 - none ,\n",
      "19 - none ,\n",
      "20 - none ,\n",
      "33 - none .\n",
      "34 - none .\n",
      "35 - . .\n",
      "45 - none ,\n",
      "46 - none ,\n",
      "47 - none ,\n",
      "49 - none ,\n",
      "50 - none ,\n",
      "55 - none ,\n",
      "56 - none ,\n",
      "57 - none ,\n",
      "59 - none ,\n",
      "65 - none ,\n",
      "66 - none ,\n",
      "67 - none ,\n",
      "71 - none .\n",
      "72 - . .\n",
      "99 - none .\n",
      "100 - none .\n",
      "101 - none .\n",
      "102 - . .\n",
      "121 - none ,\n",
      "122 - none ,\n",
      "123 - none ,\n",
      "150 - none ,\n",
      "151 - none ,\n",
      "152 - none ,\n",
      "153 - none ,\n",
      "213 - none ,\n",
      "214 - none ,\n",
      "215 - none ,\n",
      "216 - none ,\n",
      "217 - none ,\n",
      "218 - none ,\n",
      "219 - none ,\n",
      "224 - none .\n",
      "225 - none .\n",
      "246 - . .\n",
      "248 - none ,\n",
      "260 - none .\n",
      "261 - none .\n",
      "262 - none .\n",
      "263 - none .\n",
      "264 - none .\n",
      "274 - none ,\n",
      "318 - none .\n",
      "432 - . .\n",
      "433 - . .\n",
      "460 - none .\n",
      "512 - none .\n",
      "513 - none .\n",
      "514 - none .\n",
      "515 - none .\n",
      "540 - none ,\n",
      "541 - none ,\n",
      "542 - none ,\n",
      "548 - none .\n",
      "549 - none .\n",
      "550 - none .\n",
      "551 - none .\n",
      "552 - none .\n",
      "553 - none .\n",
      "554 - none ,\n",
      "556 - none ,\n",
      "557 - none ,\n",
      "558 - none ,\n",
      "597 - none ,\n",
      "598 - none ,\n",
      "599 - . ,\n",
      "611 - none ,\n",
      "624 - none .\n",
      "625 - none .\n",
      "626 - none .\n",
      "627 - none .\n",
      "628 - none .\n",
      "629 - none .\n",
      "656 - none .\n",
      "688 - , ,\n",
      "691 - none .\n",
      "692 - . .\n",
      "712 - none ,\n",
      "713 - none ,\n",
      "714 - none ,\n",
      "720 - none ,\n",
      "721 - none ,\n",
      "722 - none ,\n",
      "723 - none ,\n",
      "731 - none ,\n",
      "732 - none ,\n",
      "773 - none .\n",
      "774 - none .\n",
      "775 - none .\n",
      "818 - none .\n",
      "819 - none .\n",
      "835 - none ,\n",
      "836 - none ,\n",
      "863 - none ,\n",
      "864 - none ,\n",
      "880 - none .\n",
      "924 - none ,\n",
      "925 - none ,\n",
      "926 - none ,\n",
      "928 - none ,\n",
      "933 - none .\n",
      "934 - none .\n",
      "935 - none .\n",
      "936 - . .\n",
      "937 - none ,\n",
      "938 - none ,\n",
      "954 - none ,\n",
      "955 - none ,\n",
      "956 - none ,\n",
      "957 - none ,\n",
      "987 - . ,\n",
      "1018 - none ,\n",
      "1019 - none ,\n",
      "1020 - none ,\n",
      "1021 - none ,\n",
      "1042 - none ,\n",
      "1043 - none ,\n",
      "1044 - none ,\n",
      "1045 - none ,\n",
      "1068 - none .\n",
      "1069 - none .\n",
      "1070 - none .\n",
      "1071 - . .\n",
      "1087 - none .\n",
      "1088 - none .\n",
      "1089 - none .\n",
      "1103 - none .\n",
      "1125 - none ,\n",
      "1126 - , ,\n",
      "1144 - none ,\n",
      "1145 - none ,\n",
      "1146 - none ,\n",
      "1147 - none ,\n",
      "1156 - none .\n",
      "1157 - . .\n",
      "1158 - none ,\n",
      "1159 - none ,\n",
      "1160 - none ,\n",
      "1183 - none ,\n",
      "1184 - none ,\n",
      "1192 - none .\n",
      "1193 - none .\n",
      "1194 - none .\n",
      "1195 - none .\n",
      "1196 - none .\n",
      "1211 - none ,\n",
      "1212 - none ,\n",
      "1213 - none ,\n",
      "1214 - none ,\n",
      "1238 - none ,\n",
      "1239 - none ,\n",
      "1240 - none ,\n",
      "1251 - none .\n",
      "1252 - . .\n",
      "1287 - . .\n",
      "1288 - . ,\n",
      "1289 - none ,\n",
      "1290 - none ,\n",
      "1291 - none ,\n",
      "1292 - none ,\n",
      "1293 - none ,\n",
      "1294 - none ,\n",
      "1295 - none ,\n",
      "1328 - none .\n",
      "1329 - . .\n",
      "1330 - none .\n",
      "1347 - none ,\n",
      "1348 - none ,\n",
      "1349 - none ,\n",
      "1350 - none ,\n",
      "1351 - none ,\n",
      "1352 - none ,\n",
      "1365 - none ,\n",
      "1366 - none ,\n",
      "1391 - none .\n",
      "1392 - none .\n",
      "1430 - none .\n",
      "1431 - none .\n",
      "1432 - none .\n",
      "1441 - none ,\n",
      "1442 - none ,\n",
      "1452 - none .\n",
      "1454 - none ,\n",
      "1455 - none ,\n",
      "1456 - none ,\n",
      "1472 - none ,\n",
      "1473 - none ,\n",
      "1482 - none .\n",
      "1483 - none .\n",
      "1484 - none .\n",
      "1485 - . .\n",
      "1486 - . .\n",
      "1505 - none .\n",
      "1506 - none .\n",
      "1646 - none .\n",
      "1647 - none .\n",
      "1648 - none .\n",
      "1649 - . .\n",
      "1684 - none ,\n",
      "1716 - none .\n",
      "1717 - none .\n",
      "1718 - none .\n",
      "1719 - none .\n",
      "1813 - none .\n",
      "1814 - none .\n",
      "1815 - none .\n",
      "1816 - none .\n",
      "1827 - none ,\n",
      "1828 - none ,\n",
      "1829 - none ,\n",
      "1845 - none .\n",
      "1846 - . .\n",
      "1868 - none ,\n",
      "1869 - none ,\n",
      "1870 - none ,\n",
      "1871 - none ,\n",
      "1872 - none ,\n",
      "1873 - none ,\n",
      "1885 - none ,\n",
      "1886 - none ,\n",
      "1887 - none ,\n",
      "1888 - none ,\n",
      "1901 - none .\n",
      "1902 - none .\n",
      "1903 - none .\n",
      "1921 - none .\n",
      "1922 - none .\n",
      "1923 - none .\n",
      "1924 - none .\n",
      "1944 - none .\n",
      "1945 - none .\n",
      "1946 - none .\n",
      "1947 - none .\n",
      "1948 - none .\n",
      "2013 - none ,\n",
      "2014 - none ,\n",
      "2015 - none ,\n",
      "2016 - none ,\n",
      "2043 - none ,\n",
      "2044 - none ,\n",
      "2045 - none ,\n",
      "2046 - none ,\n",
      "2073 - none ,\n",
      "2081 - none ,\n",
      "2082 - none ,\n",
      "2090 - none ,\n",
      "2096 - none .\n",
      "2097 - none .\n",
      "2098 - none .\n",
      "2099 - none ,\n",
      "2100 - none ,\n",
      "2122 - none ,\n",
      "2129 - none .\n",
      "2130 - none .\n",
      "2152 - none ,\n",
      "2153 - none ,\n",
      "2164 - none .\n",
      "2165 - none .\n",
      "2166 - . .\n"
     ]
    }
   ],
   "source": [
    "  import pandas as pd\n",
    "  \n",
    "  def simplify_label(label):\n",
    "    return label\n",
    "  \n",
    "  classes_without_O = [\",\",\".\",\"?\",\"!\"]\n",
    "\n",
    "  test_tokenized_texts, test_labels = tokenize(x_test, y_test)\n",
    "  input_ids, tags, attention_masks = pad_sentences_and_labels(test_tokenized_texts, test_labels)\n",
    "\n",
    "  val_inputs = torch.tensor(input_ids)\n",
    "  val_tags = torch.tensor(tags)\n",
    "  val_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  test_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "  test_sampler = SequentialSampler(test_data)\n",
    "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
    "  \n",
    "  \n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  predictions, true_labels = [], []\n",
    "  counter = 0\n",
    "  for batch in test_dataloader:\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "      with torch.no_grad():\n",
    "          tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "          logits = model(b_input_ids, token_type_ids=None,\n",
    "                         attention_mask=b_input_mask)\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "      true_labels.append(label_ids)\n",
    "\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "      eval_loss += tmp_eval_loss.mean().item()\n",
    "      eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "      nb_eval_examples += b_input_ids.size(0)\n",
    "      nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  print(\"Validation loss: {}\".format(eval_loss))\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps))\n",
    "  pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "  test_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "  print(\"F1-Score: {}\".format(f1_score(pred_tags, test_tags)))\n",
    "\n",
    "  y_true = pd.Series(test_tags)\n",
    "  y_pred = pd.Series(pred_tags)\n",
    "  cross_tab = pd.crosstab(y_true, y_pred, rownames=['Real Label'], colnames=['Prediction'], margins=True)\n",
    "  report = classification_report(y_true, y_pred, labels=classes_without_O, target_names=classes_without_O)\n",
    "  report_with_O = classification_report(y_true, y_pred)\n",
    "\n",
    "  t_y_true = [simplify_label(tags_vals[p_i]) for p in predictions for p_i in p]\n",
    "  t_y_pred = [simplify_label(tags_vals[l_ii]) for l in true_labels for l_i in l for l_ii in l_i]\n",
    "  \n",
    "  for i in range(2200):\n",
    "    if (t_y_pred[i]!= \"none\"):\n",
    "      print(str(i) + \" - \" + t_y_true[i] +\" \"+ t_y_pred[i])\n",
    " \n",
    "  \n",
    "  transformed_y_true = pd.Series(t_y_true)\n",
    "  transformed_y_pred = pd.Series(t_y_pred)\n",
    "\n",
    "  cross_tab_transformed = pd.crosstab(transformed_y_true, transformed_y_pred, rownames=['Real Label'], colnames=['Prediction'], margins=True)\n",
    "  report_transformed = classification_report(transformed_y_true, transformed_y_pred, labels=classes_without_O, target_names=classes_without_O)\n",
    "  report_with_O_transformed = classification_report(transformed_y_true, transformed_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2156,
     "status": "ok",
     "timestamp": 1555876260934,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "7DqDG-rYcx1i",
    "outputId": "5dcb499c-5016-4643-a670-f340baf24471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ,       0.47      0.04      0.08      1397\n",
      "           .       0.63      0.15      0.24       882\n",
      "           ?       0.00      0.00      0.00         0\n",
      "           !       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.57      0.08      0.14      2281\n",
      "   macro avg       0.27      0.05      0.08      2281\n",
      "weighted avg       0.53      0.08      0.14      2281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1555879737473,
     "user": {
      "displayName": "Moshe Noi",
      "photoUrl": "",
      "userId": "09037760404551320411"
     },
     "user_tz": -180
    },
    "id": "TwYasNTGqGcv",
    "outputId": "75aab8dc-540f-4872-bb2f-ac605cf8682f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           !       0.00      0.00      0.00         2\n",
      "           ,       0.47      0.04      0.08      1397\n",
      "           .       0.63      0.15      0.24       882\n",
      "        none       0.89      1.00      0.94     17319\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     19600\n",
      "   macro avg       0.50      0.30      0.31     19600\n",
      "weighted avg       0.85      0.89      0.85     19600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_with_O)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Heb_Punc.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
